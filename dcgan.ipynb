{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f56013eec70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "seed = 999\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader(object):\n",
    "    def __init__(self, path, image_size, batch_size):\n",
    "        dataset = datasets.ImageFolder(root=path, transform=transforms.Compose([\n",
    "                                                    transforms.Resize(image_size),\n",
    "                                                    transforms.CenterCrop(image_size),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ]))\n",
    "\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def show(self):\n",
    "        _, one_batch = next(enumerate(self.dataloader))\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Real Images\")\n",
    "        plt.imshow(np.transpose(make_grid(one_batch[0][:64], padding=2, normalize=True), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(\"./data/celeba\", image_size=64, batch_size=512)\n",
    "dataloader.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model):\n",
    "    layer_name = model.__class__.__name__\n",
    "    if layer_name.find('Conv') != -1:\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "    elif layer_name.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_input, n_kernels, im_size=(3, 64, 64)):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_input, n_kernels * 8, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(n_kernels * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(n_kernels * 8, n_kernels * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_kernels * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(n_kernels * 4, n_kernels * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_kernels * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(n_kernels * 2, n_kernels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_kernels),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(n_kernels, im_size[0], kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "            #out size 3 x 64 x 64\n",
    "        )\n",
    "        self.apply(init_weights)    \n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.main(X)\n",
    "\n",
    "    def print(self):\n",
    "        print(self)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_kernels, im_size=(3, 64, 64)):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(im_size[0], n_kernels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(n_kernels, n_kernels * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_kernels * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(n_kernels * 2, n_kernels * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_kernels * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(n_kernels * 4, n_kernels * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_kernels * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(n_kernels * 8, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.apply(init_weights)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.main(X)\n",
    "\n",
    "    def print(self):\n",
    "        print(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, dataloader, in_size, modelG, modelD, lr=0.0002, im_size=(3, 64, 64)):\n",
    "        self.dataloader = dataloader\n",
    "        self.modelG = modelG\n",
    "        self.modelD = modelD\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.in_size = in_size\n",
    "\n",
    "        #Create fixed random noise vector to generate evaluation images during training\n",
    "        self.fixed_noise_vector = torch.randn(64, in_size, 1, 1)\n",
    "        if torch.cuda.is_available():\n",
    "            self.fixed_noise_vector = self.fixed_noise_vector.cuda()\n",
    "\n",
    "        #label convention from original GAN paper\n",
    "        self.real_label = 1\n",
    "        self.fake_label = 0\n",
    "\n",
    "        #optimizers\n",
    "        self.optimizerG = optim.Adam(modelG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "        self.optimizerD = optim.Adam(modelD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    def train(self, epochs):\n",
    "        if torch.cuda.is_available():\n",
    "            self.modelG.cuda()\n",
    "            self.modelD.cuda()\n",
    "        # Structures to store the training progress\n",
    "        self.img_list = []\n",
    "        self.G_losses = []\n",
    "        self.D_losses = []\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc='Epochs'):\n",
    "            for i, real_data in enumerate(tqdm(self.dataloader, desc='Batches'), 0):\n",
    "                ################Discriminator####################\n",
    "\n",
    "                #Objective Function: log(D(x)) + log(1 - D(G(z)))\n",
    "                self.modelD.zero_grad()\n",
    "                #real data batch\n",
    "                batch_size = len(real_data[0])\n",
    "                labels = torch.full((batch_size,), self.real_label)\n",
    "                if torch.cuda.is_available():\n",
    "                    real_data, labels = real_data[0].cuda(), labels.cuda()\n",
    "\n",
    "                y = self.modelD(real_data).view(-1)\n",
    "                #real data loss on discriminator\n",
    "                lossD_real = self.criterion(y, labels)\n",
    "                lossD_real.backward()\n",
    "                D_x = y.mean().item()\n",
    "\n",
    "                #fake data batch\n",
    "                noise_vectors = torch.randn(batch_size, self.in_size, 1, 1)\n",
    "                if torch.cuda.is_available():\n",
    "                    noise_vectors = noise_vectors.cuda()\n",
    "                \n",
    "                #generate fake images\n",
    "                fakes = self.modelG(noise_vectors)\n",
    "                labels.fill_(self.fake_label)\n",
    "                y = self.modelD(fakes).view(-1)\n",
    "                #fake data loss on discriminator\n",
    "                lossD_fake = self.criterion(y, labels)\n",
    "                lossD_fake.backward(retain_graph=True)\n",
    "                D_G_z1 = y.mean().item()\n",
    "                #final discriminator loss\n",
    "                lossD = lossD_real + lossD_fake\n",
    "                #update\n",
    "                self.optimizerD.step()\n",
    "\n",
    "                ##############Generator#######################\n",
    "\n",
    "                #Objective function: log(D(G(z)))\n",
    "                self.modelG.zero_grad()\n",
    "                labels.fill_(self.real_label) #the generator loss consider the fake images as real\n",
    "                #regenerate the discriminator prediction with its updated version\n",
    "                y = self.modelD(fakes).view(-1)\n",
    "                #generator loss\n",
    "                lossG = self.criterion(y, labels)\n",
    "                lossG.backward()\n",
    "                D_G_z2 = y.mean().item()\n",
    "                #update\n",
    "                self.optimizerG.step()\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    tqdm.write(\"[%d/%d][%d/%d] LossD: %.4f LossG: %.4f D(x): %.4f D(G(z)): %.4f -> %.4f\" % (epoch, epochs, i, len(self.dataloader), lossD.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "                self.G_losses.append(lossG.item())\n",
    "                self.D_losses.append(lossD.item())\n",
    "\n",
    "                if count % 1000 == 0 or (epoch == epochs - 1 and i == len(self.dataloader) - 1):\n",
    "                    with torch.no_grad():\n",
    "                        fakes = self.modelG(self.fixed_noise_vector).detach().cpu()\n",
    "                    self.img_list.append(make_grid(fakes, padding=2, normalize=True))\n",
    "                    plt.figure(figsize=(8,8))\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.imshow(np.transpose(self.img_list[-1], (1,2,0)))\n",
    "\n",
    "                count += 1\n",
    "\n",
    "    def print_losses(self):\n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.plot(self.G_losses, lable=\"Generator\")\n",
    "        plt.plot(self.D_losses, lable=\"Discriminator\")\n",
    "        plt.xlable(\"iterations\")\n",
    "        plt.ylable(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(100, 64)\n",
    "dis = Discriminator(64)\n",
    "trainer = Trainer(dataloader.dataloader, 100, modelG=gen, modelD=dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pytorch': virtualenv)",
   "language": "python",
   "name": "python361064bitpytorchvirtualenvd59703a1036943fe8cb882f2eefa042e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
